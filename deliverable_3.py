# -*- coding: utf-8 -*-
"""Deliverable 3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QMuUv8d00vcG19_4diSvcDgAx_ic4pEC
"""

from google.colab import drive
drive.mount("/content/drive/", force_remount=True)

import os
os.chdir(r"/content/drive/My Drive/McGill/Winter 2020/MAIS 202 Bootcamp/Final Project")

!pwd

"""# Importing Third Party Libraries"""

pip install transformers

import csv
import json
import numpy as np
from transformers import BertTokenizer, BertForQuestionAnswering
import torch
import tensorflow as tf

"""# Preprocessing"""

train_file = open("train-v2.0.json", "r")

train_string = train_file.read()

train_dict = json.loads(train_string)

# assign the list of all articles to data_list
# format: list of dicts. keys: "title", "paragraphs"
# "title": str
# "paragraphs": list of dictionaries associated to a given context
# in each dict: "qas": list of dicts, "context": str
# "qas": list of dicts. in each dict: "question": str, "id": str, "answers": list of 1 dict w/ "text" and "answer_start", "is_impossible": False 
train_data = train_dict["data"]

# splitting data
# question ids
# question context pairs
# correct answers

question_ids_temp = []
questions_contexts_temp = []
correct_answers_temp = []

sample_rate = 25

for article in train_data:
  for paragraph in article["paragraphs"]:
    context = paragraph["context"]

    for qaset in paragraph["qas"]:

      question_id = qaset["id"]
      question_ids_temp.append(question_id)

      question = qaset["question"]
      questions_contexts_temp.append((question, context))

      if qaset["is_impossible"]:
        answer = ""
      else:
        answer = qaset["answers"]
        answer = answer[0]["text"]
      correct_answers_temp.append(answer)

# questions_contexts_temp is a list of tuples

print(len(questions_contexts_temp))

question_ids = []
questions_contexts = []
correct_answers = []

for i in range(0, len(question_ids_temp), sample_rate):
  question_ids.append(question_ids_temp[i])
  questions_contexts.append(questions_contexts_temp[i])
  correct_answers.append(correct_answers_temp[i])

print(question_ids[:3])
print(questions_contexts[:3])
print(correct_answers[:3])

print(len(question_ids))

def train_validation_test_split(X, y):
  X_train = X[:int(len(X) * 0.6)]
  y_train = y[:int(len(y) * 0.6)]
  X_valid = X[int(len(X) * 0.6):int(len(X) * 0.8)]
  y_valid = y[int(len(y) * 0.6):int(len(y) * 0.8)]
  X_test = X[int(len(X) * 0.8):]
  y_test = y[int(len(y) * 0.8):]
  return X_train, y_train, X_valid, y_valid, X_test, y_test

# X_train, y_train, X_valid, y_valid, X_test, y_test = train_validation_test_split(questions_contexts, correct_answers)

"""# Tokenization"""

tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')

# tokenize the strings and get the ids of each tokenized tokens
# aka convert "how are you?", "good" --> [101, 203, 900, 400, 10003, 102, 600, 102]
def questions_contexts_to_input_ids(question, context):
  
  input_ids = tokenizer.encode(question, context, max_length=512)

  return input_ids

# get the token id (0 if question, 1 if answer) for example
# [0, 0, 0, 0, 0, 0, 1, 1]
def find_token_type_ids(input_ids):

  token_type_ids = [0 if i <= input_ids.index(102) else 1 for i in range(len(input_ids))]

  return token_type_ids

"""# Model Implementation"""

model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')

def find_answer_indices(input_ids, token_type_ids):
  start_index, end_index = model(torch.tensor([input_ids]), token_type_ids=torch.tensor([token_type_ids]))
  return start_index, end_index

answer_predictions = []



"""RuntimeError: index out of range: Tried to access index 512 out of table with 511 rows. at /pytorch/aten/src/TH/generic/THTensorEvenMoreMath.cpp:418 site:stackoverflow.com"""

# find one question with an impossible answer in the first 1000 questions

for i in range(1000):
  if correct_answers[i] == "":
    print(i, end=" ")

n = 0

for question, context in questions_contexts:

  input_ids = questions_contexts_to_input_ids(question, context)
  token_type_ids = find_token_type_ids(input_ids)

  # use pre-trained BERT model to find the answer start and end indices
  start_index, end_index = find_answer_indices(input_ids, token_type_ids)

  # screen for impossible questions by using 6 as a minimum

  impossible_question = True

  # for j in range(len(start_index[0])):
    # if start_index[0][j].item() > 6:
      # impossible_question = False

  print(n)
  print("Max values:", torch.max(start_index).item(), torch.max(end_index).item())
  print("Min values:", torch.min(start_index).item(), torch.min(end_index).item())
  print("Avg values:", torch.mean(start_index).item(), torch.mean(end_index).item())


  if torch.max(start_index).item() > 6 or torch.max(end_index).item() > 6:
    impossible_question = False

  # append predicted answer, depending on if it's an impossible question

  if impossible_question:
    answer_predictions.append("")

  else:

    # convert [101, 203, 900, 400, 10003, 102, 600, 102] to
    #  ["[CLS]", "how", "are", "you", "?", "[SEP]", "good", "[SEP]"]
    # all_tokens = tokenizer.convert_ids_to_tokens(input_ids)
    # answer = ' '.join(all_tokens[torch.argmax(start_index) : torch.argmax(end_index)+1])


    answer_ids = input_ids[torch.argmax(start_index) : torch.argmax(end_index)+1]
    answer = tokenizer.decode(answer_ids)

    answer_predictions.append(answer)
  
  n += 1

# impossible questions: 600 602 603 604 611 614 615 616 617 620 621 623 625 661 664 665 667 670 672 674 675 676 677 678 681 682 683 685 686 687 688 689 690 691 694 695 696 698 699

print(len(questions_contexts))
print(correct_answers[:500])
print(len(answer_predictions))

"""# Postprocessing"""

# predictions for each question given the question id

predictions = {}
corrects = {}


for i in range(len(question_ids)):
  predictions[question_ids[i]] = answer_predictions[i]
  corrects[question_ids[i]] = correct_answers[i]
  
print(corrects)
print(predictions)

# saving correct answers to a json file

"""
with open("correct_answrs.json", "w") as corrects_file:
  json.dump(corrects, corrects_file, indent=4)
"""

# saving predictions 0
# does not screen for impossible answers ie. assumes all questions have possible answers

"""
with open("answr_predictions0.json", "w") as pred0_file:
  json.dump(predictions, pred0_file, indent=4)
"""

# saving predictions 1 to a json
# torch.max(start_index).item() > 6 OR torch.max(end_index).item() > 6

"""
with open("answr_predictions1.json", "w") as pred1_file:
  json.dump(predictions, pred1_file, indent=4)
"""

# saving pred 2
# torch.max(start_index).item() > 6.5 AND torch.max(end_index).item() > 6.5

"""
with open("answr_predictions2.json", "w") as pred2_file:
  json.dump(predictions, pred2_file, indent=4)
"""

# saving pred 3
# torch.max(start_index).item() > 6.5 OR torch.max(end_index).item() > 6.5

"""
with open("answr_predictions3.json", "w") as pred3_file:
  json.dump(predictions, pred3_file, indent=4)
"""

# saving pred 4
# torch.max(start_index).item() > 7 OR torch.max(end_index).item() > 7.5

"""
with open("answr_predictions4.json", "w") as pred4_file:
  json.dump(predictions, pred4_file, indent=4)
"""

# saving corrects test

with open("correct_tests.json", "w") as corrects_test:
  json.dump(corrects, corrects_test, indent=4)

# saving test 1
# > 6 OR > 6

with open("answr_test1.json", "w") as test1_file:
  json.dump(predictions, test1_file, indent=4)